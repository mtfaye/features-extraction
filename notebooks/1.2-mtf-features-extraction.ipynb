{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "The next step is to create features from the raw text so we can train the machine learning models. The steps followed are:\n",
    "\n",
    "Text Cleaning and Preparation: cleaning of special characters, downcasing, punctuation signs. possessive pronouns and stop words removal and lemmatization.\n",
    "- Label coding: creation of a dictionary to map each category to a code.\n",
    "- Train-test split: to test the models on unseen data.\n",
    "- Text representation: use of TF-IDF scores to represent text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put here the path of the json file saved from src/data/data_processing.py\n",
    "data_folder_path = '/Users/mouhamethtakhafaye/Desktop/behavox_assignment/notebooks/Pickles/clean_corpus.pickle'\n",
    "data_folder_path_2 = '/Users/mouhamethtakhafaye/Desktop/behavox_assignment/notebooks/Pickles/raw_corpus.pickle'\n",
    "\n",
    "# Path for outfiles\n",
    "outfile_path = '/Users/mouhamethtakhafaye/Desktop/behavox_assignment/notebook/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(data_folder_path, 'rb') as data:\n",
    "    clean_corpus = pickle.load(data)\n",
    "with open(data_folder_path_2, 'rb') as f:\n",
    "    raw_corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHATS</th>\n",
       "      <td>hello                             morning                             yeah      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAILS</th>\n",
       "      <td>please let  know   still need curve shift  thanks heather  original message   allen phillip k   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMS</th>\n",
       "      <td>sms                                      hi ina                             ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Messages\n",
       "CHATS                   hello                             morning                             yeah      ...\n",
       "EMAILS  please let  know   still need curve shift  thanks heather  original message   allen phillip k   ...\n",
       "SMS                         sms                                      hi ina                             ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHATS</th>\n",
       "      <td>\\n                Hello?\\n             \\n                Morning\\n             \\n               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAILS</th>\n",
       "      <td>Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMS</th>\n",
       "      <td>\\n                    Sms #2\\n                 \\n                    Hi Ina! How are you?\\n     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               Raw_Messages\n",
       "CHATS   \\n                Hello?\\n             \\n                Morning\\n             \\n               ...\n",
       "EMAILS  Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- F...\n",
       "SMS     \\n                    Sms #2\\n                 \\n                    Hi Ina! How are you?\\n     ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_corpus = raw_corpus.rename(columns={'Messages': 'Raw_Messages'})\n",
    "raw_corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Messages</th>\n",
       "      <th>Raw_Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHATS</td>\n",
       "      <td>hello                             morning                             yeah      ...</td>\n",
       "      <td>\\n                Hello?\\n             \\n                Morning\\n             \\n               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMAILS</td>\n",
       "      <td>please let  know   still need curve shift  thanks heather  original message   allen phillip k   ...</td>\n",
       "      <td>Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMS</td>\n",
       "      <td>sms                                      hi ina                             ...</td>\n",
       "      <td>\\n                    Sms #2\\n                 \\n                    Hi Ina! How are you?\\n     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel  \\\n",
       "0   CHATS   \n",
       "1  EMAILS   \n",
       "2     SMS   \n",
       "\n",
       "                                                                                              Messages  \\\n",
       "0                  hello                             morning                             yeah      ...   \n",
       "1  please let  know   still need curve shift  thanks heather  original message   allen phillip k   ...   \n",
       "2                      sms                                      hi ina                             ...   \n",
       "\n",
       "                                                                                          Raw_Messages  \n",
       "0  \\n                Hello?\\n             \\n                Morning\\n             \\n               ...  \n",
       "1  Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- F...  \n",
       "2  \\n                    Sms #2\\n                 \\n                    Hi Ina! How are you?\\n     ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_corpus = clean_corpus.join(raw_corpus).reset_index()\n",
    "df = combined_corpus.rename(columns={'index': 'Channel'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Label coding\n",
    "We'll create a dictionary with the label codification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_code = {\n",
    "    'SMS': 1,\n",
    "    'EMAILS': 2,\n",
    "    'CHATS': 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category mapping\n",
    "df['Channel_code'] = df['Channel']\n",
    "df = df.replace({'Channel_code': channel_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Messages</th>\n",
       "      <th>Raw_Messages</th>\n",
       "      <th>Channel_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHATS</td>\n",
       "      <td>hello                             morning                             yeah      ...</td>\n",
       "      <td>\\n                Hello?\\n             \\n                Morning\\n             \\n               ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMAILS</td>\n",
       "      <td>please let  know   still need curve shift  thanks heather  original message   allen phillip k   ...</td>\n",
       "      <td>Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- F...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMS</td>\n",
       "      <td>sms                                      hi ina                             ...</td>\n",
       "      <td>\\n                    Sms #2\\n                 \\n                    Hi Ina! How are you?\\n     ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel  \\\n",
       "0   CHATS   \n",
       "1  EMAILS   \n",
       "2     SMS   \n",
       "\n",
       "                                                                                              Messages  \\\n",
       "0                  hello                             morning                             yeah      ...   \n",
       "1  please let  know   still need curve shift  thanks heather  original message   allen phillip k   ...   \n",
       "2                      sms                                      hi ina                             ...   \n",
       "\n",
       "                                                                                          Raw_Messages  \\\n",
       "0  \\n                Hello?\\n             \\n                Morning\\n             \\n               ...   \n",
       "1  Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- F...   \n",
       "2  \\n                    Sms #2\\n                 \\n                    Hi Ina! How are you?\\n     ...   \n",
       "\n",
       "   Channel_code  \n",
       "0             3  \n",
       "1             2  \n",
       "2             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train - test split\n",
    "We'll set apart a test set to prove the quality of our models. We'll do Cross Validation in the train set in order to tune the hyperparameters and then test performance on the unseen data of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Messages'], \n",
    "                                                    df['Channel_code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have much observations (only 2.225), we'll choose a test set size of 15% of the full dataset.\n",
    "\n",
    "## 4. Text representation\n",
    "We have various options:\n",
    "\n",
    "Count Vectors as features\n",
    "TF-IDF Vectors as features\n",
    "Word Embeddings as features\n",
    "Text / NLP based features\n",
    "Topic Models as features\n",
    "We'll use TF-IDF Vectors as features.\n",
    "\n",
    "We have to define the different parameters:\n",
    "\n",
    "- ngram_range: We want to consider both unigrams and bigrams.\n",
    "- max_df: When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
    "- min_df: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "- max_features: If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "- See TfidfVectorizer? for further detail.\n",
    "\n",
    "It needs to be mentioned that we are implicitly scaling our data when representing it as TF-IDF features with the argument norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "# We have chosen these values as a first approximation.\n",
    "ngram_range = (1,2)\n",
    "min_df = 1\n",
    "max_df = 1\n",
    "max_features = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 400)\n",
      "(1, 400)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'CHATS' category:\n",
      "  . Most correlated unigrams:\n",
      ". yeah\n",
      ". chart\n",
      ". trading\n",
      ". short\n",
      ". im\n",
      "  . Most correlated bigrams:\n",
      ". strong buy\n",
      ". hi john\n",
      "\n",
      "# 'EMAILS' category:\n",
      "  . Most correlated unigrams:\n",
      ". yeah\n",
      ". chart\n",
      ". trading\n",
      ". short\n",
      ". im\n",
      "  . Most correlated bigrams:\n",
      ". strong buy\n",
      ". hi john\n",
      "\n",
      "# 'SMS' category:\n",
      "  . Most correlated unigrams:\n",
      ". future\n",
      ". full\n",
      ". friday\n",
      ". guys\n",
      ". zdnet\n",
      "  . Most correlated bigrams:\n",
      ". gas intelligence\n",
      ". full story\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Product, channel_id in sorted(channel_code.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == channel_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proprietary otherwise',\n",
       " 'products services',\n",
       " 'privileged proprietary',\n",
       " 'private information',\n",
       " 'primary account',\n",
       " 'price save',\n",
       " 'read price',\n",
       " 'requested mattsmithenroncom',\n",
       " 'request request',\n",
       " 'request pending',\n",
       " 'request id',\n",
       " 'request create',\n",
       " 'remove email',\n",
       " 'recipient may',\n",
       " 'received error',\n",
       " 'otherwise private',\n",
       " 'original use',\n",
       " 'original message',\n",
       " 'november pm',\n",
       " 'notify sender',\n",
       " 'please visit',\n",
       " 'please use',\n",
       " 'please try',\n",
       " 'please reply',\n",
       " 'please notify',\n",
       " 'please note',\n",
       " 'please let',\n",
       " 'please contact',\n",
       " 'please click',\n",
       " 'phillip allen',\n",
       " 'phase first',\n",
       " 'resource name',\n",
       " 'upgraded strong',\n",
       " 'td typeblock',\n",
       " 'td td',\n",
       " 'upon request',\n",
       " 'use email',\n",
       " 'would like',\n",
       " 'web site',\n",
       " 'vpn octel',\n",
       " 'resource type',\n",
       " 'sender immediately',\n",
       " 'save see',\n",
       " 'risk acceptance',\n",
       " 'rights reserved',\n",
       " 'rights permanent',\n",
       " 'review act',\n",
       " 'strong buy',\n",
       " 'ssn tin',\n",
       " 'ssn ssn',\n",
       " 'six digits',\n",
       " 'coverage initiated',\n",
       " 'contain privileged',\n",
       " 'confidential information',\n",
       " 'common stock',\n",
       " 'create date',\n",
       " 'direct dial',\n",
       " 'dial vpn',\n",
       " 'designated recipient',\n",
       " 'delete original',\n",
       " 'dear phillip',\n",
       " 'days please',\n",
       " 'date requested',\n",
       " 'approval days',\n",
       " 'allen phillip',\n",
       " 'account holder',\n",
       " 'buy strong',\n",
       " 'buy buy',\n",
       " 'dow jones',\n",
       " 'know questions',\n",
       " 'jones interactive',\n",
       " 'intended recipient',\n",
       " 'intelligence press',\n",
       " 'initiated buy',\n",
       " 'information received',\n",
       " 'last six',\n",
       " 'immediately delete',\n",
       " 'let know',\n",
       " 'message remove',\n",
       " 'message designated',\n",
       " 'may contain',\n",
       " 'mattsmithenroncom resource',\n",
       " 'make sure',\n",
       " 'forms local',\n",
       " 'error please',\n",
       " 'enron corp',\n",
       " 'email prohibited',\n",
       " 'downgraded buy',\n",
       " 'hunter williams',\n",
       " 'hi john',\n",
       " 'zd inc',\n",
       " 'grande communications',\n",
       " 'gas intelligence',\n",
       " 'full story']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is more bigrams. This means with a higher number of features in our parameter, the bigrams have more correlation with the category than the unigrams, and since we're restricting the number of features to the most representative 300, only a few bigrams are being considered.\n",
    "\n",
    "Let's save the files we'll need in the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "with open('Pickles/X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "    \n",
    "# X_test    \n",
    "with open('Pickles/X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# y_train\n",
    "with open('Pickles/y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(y_train, output)\n",
    "    \n",
    "# y_test\n",
    "with open('Pickles/y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(y_test, output)\n",
    "    \n",
    "# df\n",
    "with open('Pickles/df.pickle', 'wb') as output:\n",
    "    pickle.dump(df, output)\n",
    "    \n",
    "# features_train\n",
    "with open('Pickles/features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('Pickles/labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('Pickles/features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "\n",
    "# labels_test\n",
    "with open('Pickles/labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('Pickles/tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
