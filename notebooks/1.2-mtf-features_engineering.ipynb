{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering \n",
    "The next step is to extract features and we have various options for that:\n",
    "\n",
    "- Count Vectors as features\n",
    "- TF-IDF Vectors as features\n",
    "- Word Embeddings as features\n",
    "- Text / NLP based features\n",
    "- Topic Modeling as features\n",
    "\n",
    "Once the feature extraction technique is applied, our job as a human is to interpret the results and see if the mix of words in each channel makes sense. If they don't make sense, we can try changing up the number of topics, the terms in the document-term matrix, model parameters or even try a different model.\n",
    "\n",
    "For this notebook, We'll try first CountVectors: \n",
    "- Why TFIDF vectorizer? \n",
    "The goal is to scale down the impact of tokens that occur very frequently in our corpus and that affect negatively our analysis. We have noticed lot of repeated words in the emails folder for instance words like Hi, Thanks, How are you etc are very frequent. TF-IDF vectorizer will hopefully helps reduce noises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for outfiles\n",
    "outfile_ = '/Users/mouhamethtakhafaye/Desktop/behavox_assignment/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('Pickles/clean_corpus.pickle', 'rb') as data:\n",
    "    clean_corpus = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SMS</th>\n",
       "      <td>sms                                      hi ina                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHATS</th>\n",
       "      <td>hello                             morning                             yeah      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAILS</th>\n",
       "      <td>please let  know   still need curve shift  thanks heather  original message    phillip    sent f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Messages\n",
       "SMS                         sms                                      hi ina                             ...\n",
       "CHATS                   hello                             morning                             yeah      ...\n",
       "EMAILS  please let  know   still need curve shift  thanks heather  original message    phillip    sent f..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_corpus.reset_index().rename(columns={'index': 'Channel'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMS</td>\n",
       "      <td>sms                                      hi ina                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHATS</td>\n",
       "      <td>hello                             morning                             yeah      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMAILS</td>\n",
       "      <td>please let  know   still need curve shift  thanks heather  original message    phillip    sent f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel  \\\n",
       "0     SMS   \n",
       "1   CHATS   \n",
       "2  EMAILS   \n",
       "\n",
       "                                                                                              Messages  \n",
       "0                      sms                                      hi ina                             ...  \n",
       "1                  hello                             morning                             yeah      ...  \n",
       "2  please let  know   still need curve shift  thanks heather  original message    phillip    sent f...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Label coding\n",
    "We'll create a dictionary with the label codification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_code = {\n",
    "    'SMS': 1,\n",
    "    'EMAILS': 2,\n",
    "    'CHATS': 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication Channel mapping\n",
    "df['Channel_code'] = df['Channel']\n",
    "df = df.replace({'Channel_code': channel_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Channel', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messages</th>\n",
       "      <th>Channel_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sms                                      hi ina                             ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello                             morning                             yeah      ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please let  know   still need curve shift  thanks heather  original message    phillip    sent f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              Messages  \\\n",
       "0                      sms                                      hi ina                             ...   \n",
       "1                  hello                             morning                             yeah      ...   \n",
       "2  please let  know   still need curve shift  thanks heather  original message    phillip    sent f...   \n",
       "\n",
       "   Channel_code  \n",
       "0             1  \n",
       "1             3  \n",
       "2             2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Count Vectorizer:\n",
    "\n",
    "We have to define the different parameters:\n",
    "\n",
    "- ngram_range: We want to consider both unigrams and bigrams.\n",
    "- max_df: When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
    "- min_df: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "- max_features: If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reminder: \n",
    "There is a big imbalance in term of text size between the 3 channels of communication. We have more files in the emails folder than the chats and sms folders and as a result of effect the most meaningfull bigrams or trigrams will come from the email channel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(stop_words=None, \n",
    "                            analyzer='word',\n",
    "                            ngram_range=(3, 3),\n",
    "                            max_df=0.80,\n",
    "                            min_df=0.3, \n",
    "                            token_pattern=r\"(?u)\\b\\w+\\b\", \n",
    "                            max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_mat = count_vec.fit_transform(df.Messages)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_mat = tfidf_transformer.fit_transform(dt_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# count_vec.get_feature_names()   uncomment to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = pd.DataFrame(dt_mat.todense(), index=df.index, columns=count_vec.get_feature_names())\n",
    "trigrams['channel_code'] = df.Channel_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able give forecast</th>\n",
       "      <th>able golf friday</th>\n",
       "      <th>able stay within</th>\n",
       "      <th>able well get</th>\n",
       "      <th>abn amro coverage</th>\n",
       "      <th>abn amro downgraded</th>\n",
       "      <th>accelerated distribution psa</th>\n",
       "      <th>accelerating distribution psa</th>\n",
       "      <th>accenture houston parkway</th>\n",
       "      <th>accenture human performance</th>\n",
       "      <th>...</th>\n",
       "      <th>是东亚地区统一的一党主权国家 也是世界上人口最多的国家 按</th>\n",
       "      <th>澳门特别行政区 下午好 嗨</th>\n",
       "      <th>照总面积计算 它是第三大或第四大国家 取决于所咨询的来源</th>\n",
       "      <th>現在 hear last</th>\n",
       "      <th>裤脚 鞋子全部打湿完了 привет</th>\n",
       "      <th>許多人需要同意 很明顯 我會等待確認</th>\n",
       "      <th>還沒有 許多人需要同意 很明顯</th>\n",
       "      <th>重庆 和香港 澳门特别行政区</th>\n",
       "      <th>鞋子全部打湿完了 привет пример</th>\n",
       "      <th>channel_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able give forecast  able golf friday  able stay within  able well get  \\\n",
       "0                   0                 0                 0              0   \n",
       "1                   1                 0                 0              0   \n",
       "2                   0                 1                 1              1   \n",
       "\n",
       "   abn amro coverage  abn amro downgraded  accelerated distribution psa  \\\n",
       "0                  0                    0                             0   \n",
       "1                  0                    0                             0   \n",
       "2                  1                    1                             1   \n",
       "\n",
       "   accelerating distribution psa  accenture houston parkway  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              1                          2   \n",
       "\n",
       "   accenture human performance  ...  是东亚地区统一的一党主权国家 也是世界上人口最多的国家 按  \\\n",
       "0                            0  ...                              0   \n",
       "1                            0  ...                              1   \n",
       "2                            3  ...                              0   \n",
       "\n",
       "   澳门特别行政区 下午好 嗨  照总面积计算 它是第三大或第四大国家 取决于所咨询的来源  現在 hear last  \\\n",
       "0              0                             0             0   \n",
       "1              1                             1             1   \n",
       "2              0                             0             0   \n",
       "\n",
       "   裤脚 鞋子全部打湿完了 привет  許多人需要同意 很明顯 我會等待確認  還沒有 許多人需要同意 很明顯  重庆 和香港 澳门特别行政区  \\\n",
       "0                   1                   0                0               0   \n",
       "1                   0                   1                1               1   \n",
       "2                   0                   0                0               0   \n",
       "\n",
       "   鞋子全部打湿完了 привет пример  channel_code  \n",
       "0                       1             1  \n",
       "1                       0             3  \n",
       "2                       0             2  \n",
       "\n",
       "[3 rows x 7269 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_long = (pd.melt(trigrams.reset_index(),id_vars=['index','channel_code'],value_name='trigram_ct').query('trigram_ct > 0')\n",
    "                 .sort_values(['index','channel_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>channel_code</th>\n",
       "      <th>variable</th>\n",
       "      <th>trigram_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>asap open email</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>better hell happened</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>call asap open</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>crapthey morons nevermind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>critical wdim 裤脚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21647</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zdnet today web</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21650</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zdnet today windows</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21653</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zero net curve</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21656</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zipper taking lead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21659</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zone please let</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7268 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  channel_code                   variable  trigram_ct\n",
       "1116       0             1            asap open email           1\n",
       "1701       0             1       better hell happened           1\n",
       "2358       0             1             call asap open           1\n",
       "4011       0             1  crapthey morons nevermind           1\n",
       "4059       0             1           critical wdim 裤脚           1\n",
       "...      ...           ...                        ...         ...\n",
       "21647      2             2            zdnet today web           1\n",
       "21650      2             2        zdnet today windows           1\n",
       "21653      2             2             zero net curve           1\n",
       "21656      2             2         zipper taking lead           1\n",
       "21659      2             2            zone please let           1\n",
       "\n",
       "[7268 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame(tfidf_mat.todense(), index=df.index, columns=count_vec.get_feature_names())\n",
    "tfidf['channel_code'] = df.Channel_code\n",
    "\n",
    "tfidf_long = pd.melt(tfidf.reset_index(), \n",
    "                     id_vars=['index','channel_code'], \n",
    "                     value_name='tfidf').query('tfidf > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = (trigrams_long.merge(tfidf_long,  on=['index','channel_code','variable']).set_index('index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7268, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_code</th>\n",
       "      <th>variable</th>\n",
       "      <th>trigram_ct</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>asap open email</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>better hell happened</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>call asap open</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>crapthey morons nevermind</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>critical wdim 裤脚</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3</td>\n",
       "      <td>alright okay alright</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3</td>\n",
       "      <td>analysis chart look</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3</td>\n",
       "      <td>another look would</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3</td>\n",
       "      <td>another opportunity enter</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>anybody thinking going</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    channel_code                   variable  trigram_ct     tfidf\n",
       "0              1            asap open email           1  0.121268\n",
       "1              1       better hell happened           1  0.121268\n",
       "2              1             call asap open           1  0.121268\n",
       "3              1  crapthey morons nevermind           1  0.121268\n",
       "4              1           critical wdim 裤脚           1  0.121268\n",
       "..           ...                        ...         ...       ...\n",
       "85             3       alright okay alright           1  0.039715\n",
       "86             3        analysis chart look           1  0.039715\n",
       "87             3         another look would           1  0.039715\n",
       "88             3  another opportunity enter           1  0.039715\n",
       "89             3     anybody thinking going           1  0.039715\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets filter 30 highest score for each channel\n",
    "fulldf.groupby('channel_code').apply(lambda x: x.nlargest(30, 'tfidf')).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
