{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Exploratory and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',150)\n",
    "from prettytable import PrettyTable # pip install prettytable\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/mouhamethtakhafaye/Desktop/behavox_assignment/src/data/01_raw.pkl' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message-ID                   object\n",
       "Date                         object\n",
       "From                         object\n",
       "To                           object\n",
       "Subject                      object\n",
       "Mime-Version                 object\n",
       "Content-Type                 object\n",
       "Content-Transfer-Encoding    object\n",
       "X-From                       object\n",
       "X-To                         object\n",
       "X-cc                         object\n",
       "X-bcc                        object\n",
       "X-Folder                     object\n",
       "X-Origin                     object\n",
       "X-FileName                   object\n",
       "Body                         object\n",
       "Cc                           object\n",
       "Bcc                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.index = raw_df['Date'].apply(pd.to_datetime)\n",
    "\n",
    "# Remove non-essential columns\n",
    "cols_to_keep = ['From', 'To', 'Cc', 'Bcc', 'Subject', 'Body']\n",
    "raw_df = raw_df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Cc</th>\n",
       "      <th>Bcc</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-12-07 10:06:42-08:00</th>\n",
       "      <td>heather.dunton@enron.com</td>\n",
       "      <td>k..allen@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RE: West Position</td>\n",
       "      <td>Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- From:  Allen, Phillip K.   Sent: Friday, December 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-30 22:49:42-08:00</th>\n",
       "      <td>anchordesk_daily@anchordesk.zdlists.com</td>\n",
       "      <td>pallen@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ANCHORDESK: Hope ahead: What I learned from 2001's tragedies</td>\n",
       "      <td>_____________________DAVID COURSEY_____________________  HOPE AHEAD: WHAT I LEARNED FROM 2001'S TRAGEDIES      As years go, 2001 sucked. But adver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-30 23:42:30-08:00</th>\n",
       "      <td>subscriptions@intelligencepress.com</td>\n",
       "      <td>pallen@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NGI Publications - Monday, December 31st 2001</td>\n",
       "      <td>Dear phillip,   This e-mail is automated notification of the availability of your current Natural Gas Intelligence Newsletter(s). Please use your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-31 02:24:51-08:00</th>\n",
       "      <td>prizemachine@feedback.iwon.com</td>\n",
       "      <td>pallen@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Click. Spin. Chances to Win up to $10,000!</td>\n",
       "      <td>[IMAGE] [IMAGE]   [IMAGE]   [IMAGE] $ 2,500 [IMAGE]   [IMAGE]  [IMAGE]      Dear  Phillip,  You've got to spin to win! Play now!     Spin the iWon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-31 10:53:43-08:00</th>\n",
       "      <td>louise.kitchen@enron.com</td>\n",
       "      <td>wes.colwell@enron.com, georgeanne.hodges@enron.com, rob.milnthorp@enron.com,\\n\\tjohn.zufferli@enron.com, peggy.hedstrom@enron.com,\\n\\tthomas.myers...</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>NETCO</td>\n",
       "      <td>The New Year has arrived and we really to finalize a lot of the work with regards to moving into NETCO.  Obviously we still do not have a deal but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              From  \\\n",
       "Date                                                                 \n",
       "2001-12-07 10:06:42-08:00                 heather.dunton@enron.com   \n",
       "2001-12-30 22:49:42-08:00  anchordesk_daily@anchordesk.zdlists.com   \n",
       "2001-12-30 23:42:30-08:00      subscriptions@intelligencepress.com   \n",
       "2001-12-31 02:24:51-08:00           prizemachine@feedback.iwon.com   \n",
       "2001-12-31 10:53:43-08:00                 louise.kitchen@enron.com   \n",
       "\n",
       "                                                                                                                                                                              To  \\\n",
       "Date                                                                                                                                                                               \n",
       "2001-12-07 10:06:42-08:00                                                                                                                                     k..allen@enron.com   \n",
       "2001-12-30 22:49:42-08:00                                                                                                                                       pallen@enron.com   \n",
       "2001-12-30 23:42:30-08:00                                                                                                                                       pallen@enron.com   \n",
       "2001-12-31 02:24:51-08:00                                                                                                                                       pallen@enron.com   \n",
       "2001-12-31 10:53:43-08:00  wes.colwell@enron.com, georgeanne.hodges@enron.com, rob.milnthorp@enron.com,\\n\\tjohn.zufferli@enron.com, peggy.hedstrom@enron.com,\\n\\tthomas.myers...   \n",
       "\n",
       "                                                Cc                      Bcc  \\\n",
       "Date                                                                          \n",
       "2001-12-07 10:06:42-08:00                      NaN                      NaN   \n",
       "2001-12-30 22:49:42-08:00                      NaN                      NaN   \n",
       "2001-12-30 23:42:30-08:00                      NaN                      NaN   \n",
       "2001-12-31 02:24:51-08:00                      NaN                      NaN   \n",
       "2001-12-31 10:53:43-08:00  john.lavorato@enron.com  john.lavorato@enron.com   \n",
       "\n",
       "                                                                                Subject  \\\n",
       "Date                                                                                      \n",
       "2001-12-07 10:06:42-08:00                                             RE: West Position   \n",
       "2001-12-30 22:49:42-08:00  ANCHORDESK: Hope ahead: What I learned from 2001's tragedies   \n",
       "2001-12-30 23:42:30-08:00                 NGI Publications - Monday, December 31st 2001   \n",
       "2001-12-31 02:24:51-08:00                    Click. Spin. Chances to Win up to $10,000!   \n",
       "2001-12-31 10:53:43-08:00                                                         NETCO   \n",
       "\n",
       "                                                                                                                                                                            Body  \n",
       "Date                                                                                                                                                                              \n",
       "2001-12-07 10:06:42-08:00  Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- From:  Allen, Phillip K.   Sent: Friday, December 0...  \n",
       "2001-12-30 22:49:42-08:00  _____________________DAVID COURSEY_____________________  HOPE AHEAD: WHAT I LEARNED FROM 2001'S TRAGEDIES      As years go, 2001 sucked. But adver...  \n",
       "2001-12-30 23:42:30-08:00  Dear phillip,   This e-mail is automated notification of the availability of your current Natural Gas Intelligence Newsletter(s). Please use your ...  \n",
       "2001-12-31 02:24:51-08:00  [IMAGE] [IMAGE]   [IMAGE]   [IMAGE] $ 2,500 [IMAGE]   [IMAGE]  [IMAGE]      Dear  Phillip,  You've got to spin to win! Play now!     Spin the iWon...  \n",
       "2001-12-31 10:53:43-08:00  The New Year has arrived and we really to finalize a lot of the work with regards to moving into NETCO.  Obviously we still do not have a deal but...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 6)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Patterns in Sender/Recipient Communications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Senders: 44\n",
      "Num Receivers: 18\n",
      "Num CC Receivers: 11\n",
      "Num BCC Receivers: 11\n"
     ]
    }
   ],
   "source": [
    "senders = raw_df['From'].unique()\n",
    "receivers = raw_df['To'].unique()\n",
    "cc_receivers = raw_df['Cc'].unique()\n",
    "bcc_receivers = raw_df['Bcc'].unique()\n",
    "\n",
    "print('Num Senders:', len(senders))\n",
    "print('Num Receivers:', len(receivers))\n",
    "print('Num CC Receivers:', len(cc_receivers))\n",
    "print('Num BCC Receivers:', len(bcc_receivers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num senders in common with receivers: 3\n",
      "Num senders who didn't receive: 41\n",
      "Num receivers who didn't send: 15\n",
      "Num senders in common with *all* receivers: 4\n"
     ]
    }
   ],
   "source": [
    "senders = set(senders)\n",
    "receivers = set(receivers)\n",
    "cc_receivers = set(cc_receivers)\n",
    "bcc_receivers = set(bcc_receivers)\n",
    "\n",
    "# Find the number of senders who were also direct receivers\n",
    "\n",
    "senders_intersect_receivers = senders.intersection(receivers)\n",
    "\n",
    "# Find the senders that didn't receive any messages\n",
    "\n",
    "senders_diff_receivers = senders.difference(receivers)\n",
    "                                           \n",
    "# Find the receivers that didn't send any messages\n",
    "\n",
    "receivers_diff_senders = receivers.difference(senders)\n",
    "\n",
    "# Find the senders who were any kind of receiver by\n",
    "# first computing the union of all types of receivers\n",
    "\n",
    "all_receivers = receivers.union(cc_receivers, bcc_receivers)\n",
    "senders_all_receivers = senders.intersection(all_receivers)\n",
    "\n",
    "print(\"Num senders in common with receivers:\", len(senders_intersect_receivers))\n",
    "print(\"Num senders who didn't receive:\", len(senders_diff_receivers))\n",
    "print(\"Num receivers who didn't send:\", len(receivers_diff_senders))\n",
    "print(\"Num senders in common with *all* receivers:\", len(senders_all_receivers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who is Sending and Receiving the Most Email?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_senders = raw_df.groupby('From')\n",
    "top_receivers = raw_df.groupby('To')\n",
    "\n",
    "top_senders = top_senders.count()['To']\n",
    "top_receivers = top_receivers.count()['From']\n",
    "\n",
    "# Get the ordered indices of the top senders and receivers in descending order\n",
    "top_snd_ord = np.argsort(top_senders)[::-1]\n",
    "top_rcv_ord = np.argsort(top_receivers)[::-1]\n",
    "\n",
    "top_senders = top_senders[top_snd_ord]\n",
    "top_receivers = top_receivers[top_rcv_ord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------+---------------+\n",
      "| Rank |                Sender               | Messages Sent |\n",
      "+------+-------------------------------------+---------------+\n",
      "|  1   |      arsystem@mailman.enron.com     |             5 |\n",
      "|  2   | subscriptions@intelligencepress.com |             4 |\n",
      "|  3   |       kirk.mcdaniel@enron.com       |             3 |\n",
      "|  4   |      mery.l.brown@accenture.com     |             3 |\n",
      "|  5   |         wise.counsel@lpl.com        |             2 |\n",
      "|  6   |        msimpkins@winstead.com       |             2 |\n",
      "|  7   |        gthorse@about-cis.com        |             2 |\n",
      "|  8   |    hunter.williams@grandecom.com    |             2 |\n",
      "|  9   |        james.bruce@enron.com        |             2 |\n",
      "|  10  |        webmaster@earnings.com       |             2 |\n",
      "+------+-------------------------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "top10 = top_senders[:10]\n",
    "pt = PrettyTable(field_names=['Rank', 'Sender', 'Messages Sent'])\n",
    "pt.align['Messages Sent'] = 'r'\n",
    "[ pt.add_row([i+1, email, vol]) for i, email, vol in zip(range(10), top10.index.values, top10.values)]\n",
    "\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = top_receivers[:10]\n",
    "pt = PrettyTable(field_names=['Rank', 'Receiver', 'Messages Received'])\n",
    "pt.align['Messages Sent'] = 'r'\n",
    "[ pt.add_row([i+1, email, vol]) for i, email, vol in zip(range(10), top10.index.values, top10.values)]\n",
    "\n",
    "#print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.Body.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2001-12-07 10:06:42-08:00    Please let me know if you still need Curve Shift.  Thanks, Heather  -----Original Message----- From:  Allen, Phillip K.   Sent: Friday, December 0...\n",
       "2001-12-30 22:49:42-08:00    _____________________DAVID COURSEY_____________________  HOPE AHEAD: WHAT I LEARNED FROM 2001'S TRAGEDIES      As years go, 2001 sucked. But adver...\n",
       "2001-12-30 23:42:30-08:00    Dear phillip,   This e-mail is automated notification of the availability of your current Natural Gas Intelligence Newsletter(s). Please use your ...\n",
       "2001-12-31 02:24:51-08:00    [IMAGE] [IMAGE]   [IMAGE]   [IMAGE] $ 2,500 [IMAGE]   [IMAGE]  [IMAGE]      Dear  Phillip,  You've got to spin to win! Play now!     Spin the iWon...\n",
       "2001-12-31 10:53:43-08:00    The New Year has arrived and we really to finalize a lot of the work with regards to moving into NETCO.  Obviously we still do not have a deal but...\n",
       "2001-12-31 17:18:31-08:00    This request has been pending your approval for  59 days.  Please click http://itcapps.corp.enron.com/srrs/auth/emailLink.asp?ID=000000000067320&P...\n",
       "2001-12-31 22:54:34-08:00    _____________________DAVID COURSEY_____________________  2002 IN REVIEW: NOT PERFECT, BUT IT SURE BEAT 2001      Welcome to my 2002 Year in Review...\n",
       "2001-12-31 15:26:05-08:00    <!-- ============================================ A SPECIAL OFFER brought to you by CBS SportsLine.com ===========================================...\n",
       "2002-01-01 14:34:36-08:00    Dear phillip,   This e-mail is automated notification of the availability of your current Natural Gas Intelligence Newsletter(s). Please use your ...\n",
       "2002-01-01 14:46:05-08:00    Dear phillip,   This e-mail is automated notification of the availability of your current Natural Gas Intelligence Newsletter(s). Please use your ...\n",
       "2002-01-01 17:19:40-08:00    This request has been pending your approval for  60 days.  Please click http://itcapps.corp.enron.com/srrs/auth/emailLink.asp?ID=000000000067320&P...\n",
       "2001-12-10 14:59:55-08:00                                                                                      Attached is the information you have requested.  Thanks, Brad Jones\n",
       "2001-09-11 10:12:32-07:00    Greg/Phillip,  Attached is the Grande Communications Service Agreement.  The business points can be found in Exhibit C.  I Can get the Non-Disturb...\n",
       "2001-09-11 14:44:51-07:00    Greg/Phillip,  I will need Two (2) executed copies of the agreement.  Hunter Williams Grande Communications 512-878-5467  >  -----Original Message...\n",
       "2001-10-10 09:03:56-07:00    Phillip, there are a number of alternative systems that will allow the same level of energy efficiency. I would wait a bit for Wink's bid though. ...\n",
       "2001-10-23 15:14:37-07:00    There are three other deals that I will fax to you.  let me know if you have an interest.  Thanks,  Jeff Smith The Smith Company 9400 Circle Drive...\n",
       "2001-10-25 13:49:57-07:00    Phillip,   Could you please do me a favor?  I would like  to read your current title policy to see what it says about easements.  You  should have...\n",
       "2001-10-25 12:04:35-07:00                                                                             Phillip,  Pursuant to your request, please see the attached.  Thanks,  Renee\n",
       "2001-10-25 13:24:44-07:00    <<3MMP10!.DOC>> Phillip,  Enclosed please find the First Amendment to Contract for your review and execution.  Please sign the Amendment at your e...\n",
       "2001-10-25 13:27:50-07:00    <<3MMPRED.DOC>> Phillip,  Enclosed please find a blackline of the First Amendment to Contract showing the revisions.  I have forwarded a clean ver...\n",
       "2001-10-26 07:29:03-07:00    Phillip & Keith  Attached is the first draw request, I will need some of these funds immediately. I think checks out of Bishops Corner, L.P. may b...\n",
       "2001-10-29 08:38:37-08:00    Hi Phillip,  This message is to confirm our meeting with you on, Tuesday, October 30th from 9:00 am - 10:00 am, the location will be EB 3267.  Att...\n",
       "2001-12-10 15:31:51-08:00    Phillip My interpretation of this is that we made $1.2Bn total, half from new deals and the other half from reserve releases, and when you back ou...\n",
       "2001-10-29 10:47:55-08:00    Phillip,  Have you found the title policy?  Thanks,  Bob Huntley   ----- Original Message ----- From: <Phillip.K.Allen@enron.com> To: <wise.counse...\n",
       "2001-10-29 09:16:09-08:00    Sheri and I would like to discuss the practice questions and graphic ideas with you for the the Knowledge System.  We wanted to get some feedback ...\n",
       "2001-10-29 14:10:02-08:00    If you cannot read this email, please click here .=20  Earnings.com - CSCO Upgrade/Downgrade History Earnings.com =09[IMAGE] =09 =09 [IMAGE] View ...\n",
       "2001-10-29 14:23:26-08:00    If you cannot read this email, please click here .=20  Earnings.com - EOG Upgrade/Downgrade History Earnings.com =09[IMAGE] =09 =09 [IMAGE] View T...\n",
       "2001-10-29 14:03:58-08:00    Amazon.com Delivers Home & Garden  [IMAGE] [IMAGE]   [IMAGE]  Home  & Garde= n   [IMAGE]  [IMAGE] Editor, Teri Kieffer  [IMAGE] October  29, 2001 ...\n",
       "2001-10-29 15:03:47-08:00    The second edition of \"New Gen Weekly\" is available for download.  The report can be found at:  O:_Dropbox/West New Gen/Weekly/2_10_26_01  If you ...\n",
       "2001-10-29 15:48:08-08:00    =20 [IMAGE]=09      [IMAGE] [IMAGE]  [IMAGE]  [IMAGE]  [IMAGE] [IMAGE]  [IMAGE]  [IMAGE]  [I= MAGE]       [IMAGE]   [IMAGE]   [IMAGE]   [IMAGE]   ...\n",
       "                                                                                                     ...                                                                          \n",
       "2001-10-29 19:06:37-08:00    eSource Presents Lexis-Nexis Training  Basic  Lexis-Nexis Basic is geared to the novice or prospective user.  You will learn the basics of getting...\n",
       "2001-10-29 21:16:58-08:00    The following reports have been waiting for your approval for more than 4 days.  Please review.  Owner: James W Reitmeyer Report Name: JReitmeyer ...\n",
       "2001-12-17 08:40:38-08:00    Phillip,  This is the proposal for the 1mm laddered muni portfolio.  These bonds are currently in inventory.  Let me know what you think.  Sincere...\n",
       "2001-12-27 14:58:02-08:00    We have for the last couple of weeks started to compile the Re-start/Integration Plans for Netco.  So far, we have primarily focussed on the mid/b...\n",
       "2001-11-02 12:18:31-08:00    Phillip,  This section pertains to terminated employees who are paid out in the year following the termination event.  The way the tax law works, ...\n",
       "2001-11-19 15:49:53-08:00    Your Internet Banking accounts are now setup again for accessing. The login id is still your main acct. # with the password being reset to the las...\n",
       "2001-11-20 10:15:25-08:00    To our IBS Customers that are still hanging in there:  We understand your continued frustration and express our sincerest apologies for our inabil...\n",
       "2001-11-23 09:11:38-08:00    Phillip Good Morning! I hope you had a wonderful Thanksgiving with your family and safe travels.  As per our meeting on Tuesday, please identify p...\n",
       "2001-11-27 08:02:04-08:00    Michelle Here are my very minor comments. However we still need to wait on any additions, based on meeting with SME's today. One concern is the fi...\n",
       "2001-11-27 08:10:09-08:00    Team FYI  Sheri The 3 SME's that have already committed to being on film need to be keep in the lope regarding the timeline. Also check with these...\n",
       "2001-11-27 11:04:59-08:00    Phillip,  Ina scheduled the conference room for tomorrow, so she's probably already got it on your schedule, but FYI - our meeting will be in the ...\n",
       "2001-11-27 11:22:36-08:00    Phillip;  This attachment is my start on your 1031 search.  From my experience, you will probably need to park the money until we find the right i...\n",
       "2001-12-29 15:02:59-08:00    Phillip;  Could you please e-mail me the draw file you created for Bishops Corner.  I was working on submitting it to you and rather then recreate...\n",
       "2001-11-27 13:20:35-08:00        Let me know if the link that I just sent for trv website doesn't work for you.     That is how I will start to publish this sheet.  -Ryan  5-3874\n",
       "2001-11-27 16:50:21-08:00    Hello: Integrity Realty Services has the following property available for sale: 1) 11815 North RR 620, Austin, Texas  78750 -- A one story retail ...\n",
       "2001-11-27 15:19:15-08:00    [IMAGE] [IMAGE]     +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ This email is not sent unsolicited. This is an Open2Win ...\n",
       "2001-11-27 17:05:30-08:00    Phillip, the insurance/repairs numbers are actually overstated; they are based on calculations from USPSL owners and agents like us who have helpe...\n",
       "2001-11-27 17:06:01-08:00    Please be advised that this information is confidential and proprietary.  We ask that this confidential information be treated as such, in accorda...\n",
       "2001-11-27 17:22:24-08:00    This request has been pending your approval for  35 days.  Please click http://itcapps.corp.enron.com/srrs/auth/emailLink.asp?ID=000000000067320&P...\n",
       "2001-11-16 10:07:13-08:00    Wow!  this looks complicated.  let me get some help on this and get back to=  you     -----Original Message----- From: =09Allen, Phillip K. =20 Se...\n",
       "2001-11-16 12:22:12-08:00    Phillip,  Thank you for meeting with us today. I want to take a few minutes to summarize the decisions that came out of our meeting.  1. Feedback ...\n",
       "2001-12-30 13:20:05-08:00    PHILLIP, Free Software now available to you from Sega, IBM, Disney, Simon & Schuster and many others!  You have been selected to receive unlimited...\n",
       "2001-11-25 19:21:47-08:00                                                    Get your FREE download of MSN Explorer at http://explorer.msn.com  - DESIGNSELECTIONS_DyalRoberts.doc\n",
       "2001-11-26 08:31:11-08:00    For purposes of an accelerated distribution from the PSA,  a \"single sum distribution,\" in Section 6.2 means that a PSA account is distributed all...\n",
       "2001-11-26 15:33:45-08:00    Phillip,  I will get a room for our Wednesday 10:00 meeting and e-mail you with the room number. FYI, our goal is to discuss the expert path (best...\n",
       "2001-11-26 15:22:12-08:00    [IMAGE]     [IMAGE]   [IMAGE] [IMAGE]   [IMAGE]         [IMAGE] [IMAGE]  [IMAGE]  [IMAGE]  [IMAGE]     [IMAGE]     Search  Amazon.com for:        ...\n",
       "2001-11-26 16:17:10-08:00    To all of our esteemed & prized Internet Banking  (IBS) Clients:  You probably have begun to wonder does anyone ever return phone calls (or e-mail...\n",
       "2001-12-30 18:33:29-08:00    [IMAGE] Get your FREE* Reward NOW! =09=09[IMAGE]=09 =09PHILLIP, this is for REAL... one of America's largest Internet companies=  has granted you ...\n",
       "NaN                          -delete Q # 1, 2, 6 -move Q #3 to scenario 5 (power plant) and make the Q be for the financial trader, Garcia -move Q #4 and #5 to scenario 9 (sto...\n",
       "NaN                          -delete Q #1, 2, 3 -move Q#4 to scenario 9 (storage) and keep it as a Q for the physical trader (Rick Lee)      Laura de la Torre Accenture Resour...\n",
       "Name: Body, Length: 68, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a first round of text cleaning techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "# Remove square brackets\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-11-27 08:02:04-08:00</th>\n",
       "      <td>michelle here are my very minor comments however we still need to wait on any additions based on meeting with smes today one concern is the firing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-10 15:31:51-08:00</th>\n",
       "      <td>phillip my interpretation of this is that we made  total half from new deals and the other half from reserve releases and when you back out the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-29 14:03:58-08:00</th>\n",
       "      <td>amazoncom delivers home  garden        home   garde n      editor teri kieffer   october           search  booksrare   used books kids booksspanis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-10 14:59:55-08:00</th>\n",
       "      <td>attached is the information you have requested  thanks brad jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-16 10:07:13-08:00</th>\n",
       "      <td>wow  this looks complicated  let me get some help on this and get back to  you     original message from  phillip k   november    am  greg lavorat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-31 02:24:51-08:00</th>\n",
       "      <td>dear  phillip  youve got to spin to win play now     spin the iwon prize machine  for chances to win  the  progressive jackpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-29 16:22:13-08:00</th>\n",
       "      <td>this request has been pending your approval for   days  please click  to review and act upon this request      request id            request creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-27 15:19:15-08:00</th>\n",
       "      <td>this email is not sent unsolicited this is an  mailing this message is sent to subscribers only the email subscription address is pallenenr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-25 12:04:35-07:00</th>\n",
       "      <td>phillip  pursuant to your request please see the attached  thanks  renee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-25 19:21:47-08:00</th>\n",
       "      <td>get your free download of msn explorer at httpexplorermsncom   designselectionsdyalrobertsdoc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                            Body\n",
       "Date                                                                                                                                                                            \n",
       "2001-11-27 08:02:04-08:00  michelle here are my very minor comments however we still need to wait on any additions based on meeting with smes today one concern is the firing...\n",
       "2001-12-10 15:31:51-08:00  phillip my interpretation of this is that we made  total half from new deals and the other half from reserve releases and when you back out the pr...\n",
       "2001-10-29 14:03:58-08:00  amazoncom delivers home  garden        home   garde n      editor teri kieffer   october           search  booksrare   used books kids booksspanis...\n",
       "2001-12-10 14:59:55-08:00                                                                                      attached is the information you have requested  thanks brad jones\n",
       "2001-11-16 10:07:13-08:00  wow  this looks complicated  let me get some help on this and get back to  you     original message from  phillip k   november    am  greg lavorat...\n",
       "2001-12-31 02:24:51-08:00                       dear  phillip  youve got to spin to win play now     spin the iwon prize machine  for chances to win  the  progressive jackpo...\n",
       "2001-10-29 16:22:13-08:00  this request has been pending your approval for   days  please click  to review and act upon this request      request id            request creat...\n",
       "2001-11-27 15:19:15-08:00         this email is not sent unsolicited this is an  mailing this message is sent to subscribers only the email subscription address is pallenenr...\n",
       "2001-10-25 12:04:35-07:00                                                                               phillip  pursuant to your request please see the attached  thanks  renee\n",
       "2001-11-25 19:21:47-08:00                                                          get your free download of msn explorer at httpexplorermsncom   designselectionsdyalrobertsdoc"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.DataFrame(df.apply(round1))\n",
    "data_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Apply a second round of cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional quotation marks and newline text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-11-27 16:50:21-08:00</th>\n",
       "      <td>hello integrity realty services has the following property available for sale   north rr  austin texas    a one story retail strip center with an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-29 09:16:09-08:00</th>\n",
       "      <td>sheri and i would like to discuss the practice questions and graphic ideas with you for the the knowledge system  we wanted to get some feedback f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-31 22:54:34-08:00</th>\n",
       "      <td>david coursey   in review not perfect but it sure beat       welcome to my  year in review column which          i feel very safe in asserting you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-10 09:03:56-07:00</th>\n",
       "      <td>phillip there are a number of alternative systems that will allow the same level of energy efficiency i would wait a bit for winks bid though you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-27 08:10:09-08:00</th>\n",
       "      <td>team fyi  sheri the  smes that have already committed to being on film need to be keep in the lope regarding the timeline also check with these  s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-29 17:35:18-08:00</th>\n",
       "      <td>this request has been pending your approval for   days  please click  to review and act upon this request      request id            request creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-27 17:22:24-08:00</th>\n",
       "      <td>this request has been pending your approval for   days  please click  to review and act upon this request      request id            request creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-09-11 10:12:32-07:00</th>\n",
       "      <td>gregphillip  attached is the grande communications service agreement  the business points can be found in exhibit c  i can get the nondisturbance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-27 15:19:15-08:00</th>\n",
       "      <td>this email is not sent unsolicited this is an  mailing this message is sent to subscribers only the email subscription address is pallenenr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-29 16:34:23-08:00</th>\n",
       "      <td>the method for distribution of the weekly reports has changed  hard copies will now be distributed through your administrative assistant    to rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                            Body\n",
       "Date                                                                                                                                                                            \n",
       "2001-11-27 16:50:21-08:00  hello integrity realty services has the following property available for sale   north rr  austin texas    a one story retail strip center with an ...\n",
       "2001-10-29 09:16:09-08:00  sheri and i would like to discuss the practice questions and graphic ideas with you for the the knowledge system  we wanted to get some feedback f...\n",
       "2001-12-31 22:54:34-08:00  david coursey   in review not perfect but it sure beat       welcome to my  year in review column which          i feel very safe in asserting you...\n",
       "2001-10-10 09:03:56-07:00  phillip there are a number of alternative systems that will allow the same level of energy efficiency i would wait a bit for winks bid though you ...\n",
       "2001-11-27 08:10:09-08:00  team fyi  sheri the  smes that have already committed to being on film need to be keep in the lope regarding the timeline also check with these  s...\n",
       "2001-10-29 17:35:18-08:00  this request has been pending your approval for   days  please click  to review and act upon this request      request id            request creat...\n",
       "2001-11-27 17:22:24-08:00  this request has been pending your approval for   days  please click  to review and act upon this request      request id            request creat...\n",
       "2001-09-11 10:12:32-07:00  gregphillip  attached is the grande communications service agreement  the business points can be found in exhibit c  i can get the nondisturbance ...\n",
       "2001-11-27 15:19:15-08:00         this email is not sent unsolicited this is an  mailing this message is sent to subscribers only the email subscription address is pallenenr...\n",
       "2001-10-29 16:34:23-08:00  the method for distribution of the weekly reports has changed  hard copies will now be distributed through your administrative assistant    to rec..."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the updated text\n",
    "data_clean = pd.DataFrame(data_clean.Body.apply(round2))\n",
    "data_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-Term Matrix\n",
    "\n",
    "For many of the techniques we'll be using in future notebooks, the text must be tokenized, meaning broken down into smaller pieces. The most common tokenization technique is to break down text into words. We can do this using scikit-learn's CountVectorizer, where every row will represent a different document and every column will represent a different word.\n",
    "\n",
    "In addition, with CountVectorizer, we can remove stop words. Stop words are common words that add no additional meaning to text such as 'a', 'the', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abn</th>\n",
       "      <th>accelerated</th>\n",
       "      <th>accelerating</th>\n",
       "      <th>accenture</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>accepted</th>\n",
       "      <th>access</th>\n",
       "      <th>accessing</th>\n",
       "      <th>accessories</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>yr</th>\n",
       "      <th>ys</th>\n",
       "      <th>yuletide</th>\n",
       "      <th>zd</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zero</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-11-26 15:33:45-08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-25 13:24:44-07:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-27 15:19:15-08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-16 12:22:12-08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-29 14:03:58-08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-25 12:04:35-07:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-29 17:35:18-08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-26 08:31:11-08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-30 22:49:42-08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           able  abn  accelerated  accelerating  accenture  \\\n",
       "Date                                                                         \n",
       "2001-11-26 15:33:45-08:00     0    0            0             0          0   \n",
       "2001-10-25 13:24:44-07:00     0    0            0             0          0   \n",
       "2001-11-27 15:19:15-08:00     0    0            0             0          0   \n",
       "2001-11-16 12:22:12-08:00     0    0            0             0          0   \n",
       "2001-10-29 14:03:58-08:00     0    0            0             0          0   \n",
       "2001-10-25 12:04:35-07:00     0    0            0             0          0   \n",
       "NaN                           0    0            0             0          1   \n",
       "2001-10-29 17:35:18-08:00     0    0            0             0          0   \n",
       "2001-11-26 08:31:11-08:00     0    0            1             1          0   \n",
       "2001-12-30 22:49:42-08:00     0    0            0             0          0   \n",
       "\n",
       "                           acceptance  accepted  access  accessing  \\\n",
       "Date                                                                 \n",
       "2001-11-26 15:33:45-08:00           0         0       0          0   \n",
       "2001-10-25 13:24:44-07:00           0         0       0          0   \n",
       "2001-11-27 15:19:15-08:00           0         0       0          0   \n",
       "2001-11-16 12:22:12-08:00           0         0       0          0   \n",
       "2001-10-29 14:03:58-08:00           0         0       0          0   \n",
       "2001-10-25 12:04:35-07:00           0         0       0          0   \n",
       "NaN                                 0         0       0          0   \n",
       "2001-10-29 17:35:18-08:00           1         0       0          0   \n",
       "2001-11-26 08:31:11-08:00           0         0       0          0   \n",
       "2001-12-30 22:49:42-08:00           0         0       0          0   \n",
       "\n",
       "                           accessories  ...  youre  youve  yr  ys  yuletide  \\\n",
       "Date                                    ...                                   \n",
       "2001-11-26 15:33:45-08:00            0  ...      0      0   0   0         0   \n",
       "2001-10-25 13:24:44-07:00            0  ...      0      0   0   0         0   \n",
       "2001-11-27 15:19:15-08:00            0  ...      0      0   0   0         0   \n",
       "2001-11-16 12:22:12-08:00            0  ...      0      0   0   0         0   \n",
       "2001-10-29 14:03:58-08:00            2  ...      0      0   0   0         1   \n",
       "2001-10-25 12:04:35-07:00            0  ...      0      0   0   0         0   \n",
       "NaN                                  0  ...      0      0   0   0         0   \n",
       "2001-10-29 17:35:18-08:00            0  ...      0      0   0   0         0   \n",
       "2001-11-26 08:31:11-08:00            0  ...      0      0   0   0         0   \n",
       "2001-12-30 22:49:42-08:00            0  ...      1      0   0   0         0   \n",
       "\n",
       "                           zd  zdnet  zero  zipper  zone  \n",
       "Date                                                      \n",
       "2001-11-26 15:33:45-08:00   0      0     0       0     0  \n",
       "2001-10-25 13:24:44-07:00   0      0     0       0     0  \n",
       "2001-11-27 15:19:15-08:00   0      0     0       0     0  \n",
       "2001-11-16 12:22:12-08:00   0      0     0       0     0  \n",
       "2001-10-29 14:03:58-08:00   0      0     0       0     0  \n",
       "2001-10-25 12:04:35-07:00   0      0     0       0     0  \n",
       "NaN                         0      0     0       0     0  \n",
       "2001-10-29 17:35:18-08:00   0      0     0       0     0  \n",
       "2001-11-26 08:31:11-08:00   0      0     0       0     0  \n",
       "2001-12-30 22:49:42-08:00   3      6     0       0     0  \n",
       "\n",
       "[10 rows x 2783 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data_clean.Body) # fit count vectorizor to our CLEAN transcript data\n",
    "\n",
    "# Convert it to an array and label all the columns\n",
    "# Can use this part for future projects\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = data_clean.index\n",
    "\n",
    "# Document-Term matrix\n",
    "data_dtm.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pickle it for later use\n",
    "data_dtm.to_pickle(\"02.dtm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also pickle the cleaned data (before we put it in document-term matrix format) and the CountVectorizer object\n",
    "data_clean.to_pickle('03.data_clean.pkl')\n",
    "pickle.dump(cv, open(\"cv.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
