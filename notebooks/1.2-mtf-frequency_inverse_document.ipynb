{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering: TF-IDF\n",
    "The next step is to extract features and we have various options for that:\n",
    "\n",
    "- Count Vectors as features\n",
    "- TF-IDF Vectors as features\n",
    "- Word Embeddings as features\n",
    "- Text / NLP based features\n",
    "- Topic Modeling as features\n",
    "\n",
    "Once the feature extraction technique is applied, our job as a human is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, we can try changing up the number of topics, the terms in the document-term matrix, model parameters, or even try a different model.\n",
    "\n",
    "For this notebook, We'll use TF-IDF Vectors as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for outfiles\n",
    "outfile_path = '/Users/mouhamethtakhafaye/Desktop/behavox_assignment/notebook/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('Pickles/clean_corpus.pickle', 'rb') as data:\n",
    "    clean_corpus = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHATS</th>\n",
       "      <td>hello                             morning                             yeah      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAILS</th>\n",
       "      <td>please let  know   still need curve shift  thanks heather  original message    phillip    sent f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMS</th>\n",
       "      <td>sms                                      hi ina                             ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Messages\n",
       "CHATS                   hello                             morning                             yeah      ...\n",
       "EMAILS  please let  know   still need curve shift  thanks heather  original message    phillip    sent f...\n",
       "SMS                         sms                                      hi ina                             ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_corpus.reset_index().rename(columns={'index': 'Channel'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHATS</td>\n",
       "      <td>hello                             morning                             yeah      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMAILS</td>\n",
       "      <td>please let  know   still need curve shift  thanks heather  original message    phillip    sent f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMS</td>\n",
       "      <td>sms                                      hi ina                             ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel  \\\n",
       "0   CHATS   \n",
       "1  EMAILS   \n",
       "2     SMS   \n",
       "\n",
       "                                                                                              Messages  \n",
       "0                  hello                             morning                             yeah      ...  \n",
       "1  please let  know   still need curve shift  thanks heather  original message    phillip    sent f...  \n",
       "2                      sms                                      hi ina                             ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Label coding\n",
    "We'll create a dictionary with the label codification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_code = {\n",
    "    'SMS': 1,\n",
    "    'EMAILS': 2,\n",
    "    'CHATS': 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication Channel mapping\n",
    "df['Channel_code'] = df['Channel']\n",
    "df = df.replace({'Channel_code': channel_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Channel', axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectors as features:\n",
    "\n",
    "We have to define the different parameters:\n",
    "\n",
    "- ngram_range: We want to consider both unigrams and bigrams.\n",
    "- max_df: When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
    "- min_df: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "- max_features: If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "- See TfidfVectorizer? for further detail.\n",
    "\n",
    "It needs to be mentioned that we are implicitly scaling our data when representing it as TF-IDF features with the argument norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter selection\n",
    "# We have chosen differents values as a first approximation and these are the ones that yield more meaningful features\n",
    "ngram_range = (1,2)\n",
    "min_df = 1\n",
    "max_df = 7\n",
    "max_features = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 200)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features = tfidf.fit_transform(df.Messages).toarray()\n",
    "labels = df.Channel_code\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'CHATS' channel:\n",
      "  . Most correlated unigrams:\n",
      ". need\n",
      ". email\n",
      ". john\n",
      ". going\n",
      ". long\n",
      ". short\n",
      "  . Most correlated bigrams:\n",
      ". downgraded buy\n",
      ". coverage initiated\n",
      ". original message\n",
      ". enron corp\n",
      ". let know\n",
      ". strong buy\n",
      "\n",
      "# 'EMAILS' channel:\n",
      "  . Most correlated unigrams:\n",
      ". click\n",
      ". hi\n",
      ". message\n",
      ". phillip\n",
      ". information\n",
      ". buy\n",
      "  . Most correlated bigrams:\n",
      ". downgraded buy\n",
      ". original message\n",
      ". coverage initiated\n",
      ". enron corp\n",
      ". let know\n",
      ". strong buy\n",
      "\n",
      "# 'SMS' channel:\n",
      "  . Most correlated unigrams:\n",
      ". hello\n",
      ". getting\n",
      ". email\n",
      ". need\n",
      ". call\n",
      ". immediately\n",
      "  . Most correlated bigrams:\n",
      ". downgraded buy\n",
      ". original message\n",
      ". coverage initiated\n",
      ". enron corp\n",
      ". let know\n",
      ". strong buy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for wrd, channel_id in sorted(channel_code.items()):\n",
    "    features_chi2 = chi2(features, labels == channel_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' channel:\".format(wrd))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-6:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-6:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['received error',\n",
       " 'buy strong',\n",
       " 'full story',\n",
       " 'please let',\n",
       " 'would like',\n",
       " 'please click',\n",
       " 'price save',\n",
       " 'may contain',\n",
       " 'intended recipient',\n",
       " 'downgraded buy',\n",
       " 'original message',\n",
       " 'coverage initiated',\n",
       " 'enron corp',\n",
       " 'let know',\n",
       " 'strong buy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is more bigrams. This means with a higher number of features in our parameter, the bigrams have more correlation with the category than the unigrams, and since we're restricting the number of features to the most representative 200, only a few bigrams are being considered.\n",
    "\n",
    "# Reminder: \n",
    "There is a big imbalance in term of text size between the 3 channels of communication. We have more files in the inbox(emails) folder than the chats and sms folders and as a result of effect the most meaningfull bigrams come from the email channel because the number of words in the chats and sms channel are very limited."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
